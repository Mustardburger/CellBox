{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cellbox\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow.compat.v1 as tf\n",
    "import shutil\n",
    "import argparse\n",
    "import json\n",
    "import glob\n",
    "import time\n",
    "from tensorflow.compat.v1.errors import OutOfRangeError\n",
    "from cellbox.utils import TimeLogger\n",
    "import pickle\n",
    "tf.disable_v2_behavior()\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "seeds = [7, 87, 62, 45, 23]\n",
    "lambdas = [(2.0, 3.0), (0.1, 0.01), (0.001, 0.0001), (0.01, 0.1), (0.0001, 0.001)]\n",
    "others = [\n",
    "    (\"tanh\", \"heun\", 100, \"by u\"),\n",
    "    (\"tanh\", \"euler\", 100, \"by u\"),\n",
    "    (\"clip linear\", \"heun\", 100, \"fix x\"),\n",
    "    (\"tanh\", \"heun\", 100, \"fix x\"),\n",
    "    (\"tanh\", \"midpoint\", 100, \"fix x\")\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize weights with correct masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_init(seed, n_x=99, n_protein_nodes=82, n_activity_nodes=87):\n",
    "    np.random.seed(seed)\n",
    "    W = np.random.normal(0.01, 1.0, size=(n_x, n_x))\n",
    "    W_mask = (1.0 - np.diag(np.ones([n_x])))\n",
    "    W_mask[n_activity_nodes:, :] = np.zeros([n_x - n_activity_nodes, n_x])\n",
    "    W_mask[:, n_protein_nodes:n_activity_nodes] = np.zeros([n_x, n_activity_nodes - n_protein_nodes])\n",
    "    W_mask[n_protein_nodes:n_activity_nodes, n_activity_nodes:] = np.zeros([n_activity_nodes - n_protein_nodes,\n",
    "                                                                            n_x - n_activity_nodes])\n",
    "\n",
    "    return W*W_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 99)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.zeros((89, 99))\n",
    "b = a[[1, 3, 5]]\n",
    "b.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize input matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_init(seed):\n",
    "    # Initialize the input by taking a slice of the actual input\n",
    "    np.random.seed(seed)\n",
    "    real_inp = pd.read_csv(\"/users/ngun7t/Documents/cellbox-jun-6/data/pert.csv\", header=None).to_numpy()\n",
    "    real_out = pd.read_csv(\"/users/ngun7t/Documents/cellbox-jun-6/data/expr.csv\", header=None).to_numpy()\n",
    "    rand_ind = np.random.choice(list(range(89)), replace=False, size=(4,)).tolist()\n",
    "    inp = real_inp[rand_ind]\n",
    "    out = real_out[rand_ind]\n",
    "    return inp, out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(89, 99)\n",
      "[44, 53, 30, 12]\n"
     ]
    }
   ],
   "source": [
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "tf.compat.v1.set_random_seed(seed)\n",
    "\n",
    "W_rand = weight_init(seed)\n",
    "inp, out = input_init(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make tensorflow model, initialize the weights, and make a forward pass with this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'experiment_id': 'Example_RP', 'model_prefix': 'seed', 'ckpt_name': 'model11.ckpt', 'export_verbose': 3, 'experiment_type': 'random partition', 'sparse_data': False, 'batchsize': 4, 'trainset_ratio': 0.7, 'validset_ratio': 0.8, 'n_batches_eval': None, 'add_noise_level': 0, 'dT': 0.1, 'ode_solver': 'heun', 'envelope_form': 'tanh', 'envelope': 0, 'pert_form': 'by u', 'ode_degree': 1, 'ode_last_steps': 2, 'n_iter_buffer': 50, 'n_iter_patience': 100, 'weight_loss': 'None', 'l1lambda': 0.0001, 'l2lambda': 0.0001, 'model': 'CellBox', 'pert_file': '/users/ngun7t/Documents/cellbox-jun-6/data/pert.csv', 'expr_file': '/users/ngun7t/Documents/cellbox-jun-6/data/expr.csv', 'node_index_file': '/users/ngun7t/Documents/cellbox-jun-6/data/node_Index.csv', 'n_protein_nodes': 82, 'n_activity_nodes': 87, 'n_x': 99, 'envelop_form': 'tanh', 'envelop': 0, 'n_epoch': 100, 'n_iter': 100, 'stages': [{'nT': 100, 'sub_stages': [{'lr_val': 0.1, 'l1lambda': 0.01, 'n_iter_patience': 1000}, {'lr_val': 0.01, 'l1lambda': 0.01}, {'lr_val': 0.01, 'l1lambda': 0.0001}, {'lr_val': 0.001, 'l1lambda': 1e-05}]}], 'ckpt_path_full': './model11.ckpt', 'drug_index': 5, 'seed': 7}\n",
      "Working directory is ready at results/Example_RP_370705d3fa02832e2d75733a602382b0.\n"
     ]
    }
   ],
   "source": [
    "def set_seed(in_seed):\n",
    "    int_seed = int(in_seed)\n",
    "    tf.compat.v1.set_random_seed(int_seed)\n",
    "    np.random.seed(int_seed)\n",
    "\n",
    "\n",
    "def prepare_workdir(in_cfg):\n",
    "    # Read Data\n",
    "    in_cfg.root_dir = os.getcwd()\n",
    "    in_cfg.node_index = pd.read_csv(in_cfg.node_index_file, header=None, names=None) \\\n",
    "        if hasattr(in_cfg, 'node_index_file') else pd.DataFrame(np.arange(in_cfg.n_x))\n",
    "\n",
    "    # Create Output Folder\n",
    "    experiment_path = 'results/{}_{}'.format(in_cfg.experiment_id, md5)\n",
    "    try:\n",
    "        os.makedirs(experiment_path)\n",
    "    except Exception:\n",
    "        pass\n",
    "    out_cfg = vars(in_cfg)\n",
    "    out_cfg = {key: out_cfg[key] for key in out_cfg if type(out_cfg[key]) is not pd.DataFrame}\n",
    "    os.chdir(experiment_path)\n",
    "    json.dump(out_cfg, open('config.json', 'w'), indent=4)\n",
    "\n",
    "    if \"leave one out\" in in_cfg.experiment_type:\n",
    "        try:\n",
    "            in_cfg.model_prefix = '{}_{}'.format(in_cfg.model_prefix, in_cfg.drug_index)\n",
    "        except Exception('Drug index not specified') as e:\n",
    "            raise e\n",
    "\n",
    "    in_cfg.working_index = in_cfg.model_prefix + \"_\" + str(working_index).zfill(3)\n",
    "\n",
    "    try:\n",
    "        shutil.rmtree(in_cfg.working_index)\n",
    "    except Exception:\n",
    "        pass\n",
    "    os.makedirs(in_cfg.working_index)\n",
    "    os.chdir(in_cfg.working_index)\n",
    "\n",
    "    with open(\"record_eval.csv\", 'w') as f:\n",
    "        f.write(\"epoch,iter,train_loss,valid_loss,train_mse,valid_mse,test_mse,time_elapsed\\n\")\n",
    "\n",
    "    print('Working directory is ready at {}.'.format(experiment_path))\n",
    "    return 0\n",
    "\n",
    "experiment_config_path = \"/users/ngun7t/Documents/cellbox-jun-6/configs_dev/Example.random_partition.CellBox.json\"\n",
    "working_index = 0\n",
    "stage = {\n",
    "    \"nT\": 100,\n",
    "    \"sub_stages\":[\n",
    "        {\"lr_val\": 0.1,\"l1lambda\": 0.01, \"n_iter_patience\":1000},\n",
    "        {\"lr_val\": 0.01,\"l1lambda\": 0.01},\n",
    "        {\"lr_val\": 0.01,\"l1lambda\": 0.0001},\n",
    "        {\"lr_val\": 0.001,\"l1lambda\": 0.00001}\n",
    "    ]}\n",
    "\n",
    "cfg = cellbox.config.Config(experiment_config_path)\n",
    "cfg.ckpt_path_full = os.path.join('./', cfg.ckpt_name)\n",
    "md5 = cellbox.utils.md5(cfg)\n",
    "cfg.drug_index = 5         # Change this for testing purposes\n",
    "cfg.seed = seed\n",
    "set_seed(seed)\n",
    "print(vars(cfg))\n",
    "\n",
    "prepare_workdir(cfg)\n",
    "logger = cellbox.utils.TimeLogger(time_logger_step=1, hierachy=3)\n",
    "args = cfg\n",
    "for i, stage in enumerate(cfg.stages):\n",
    "    set_seed(cfg.seed)\n",
    "    cfg = cellbox.dataset.factory(cfg)\n",
    "    args.sub_stages = stage['sub_stages']\n",
    "    args.n_T = stage['nT']\n",
    "    model = cellbox.model.factory(args)\n",
    "    if i == 0: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(89,)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cellbox.utils import loss, optimize\n",
    "\n",
    "class PertBio:\n",
    "    \"\"\"define abstract perturbation model\"\"\"\n",
    "    def __init__(self, args):\n",
    "        self.args = args\n",
    "        self.n_x = args.n_x\n",
    "        self.pert_in, self.expr_out = args.pert_in, args.expr_out\n",
    "        self.iter_train, self.iter_monitor, self.iter_eval = args.iter_train, args.iter_monitor, args.iter_eval\n",
    "        self.train_x, self.train_y = self.iter_train.get_next()\n",
    "        self.monitor_x, self.monitor_y = self.iter_monitor.get_next()\n",
    "        self.eval_x, self.eval_y = self.iter_eval.get_next()\n",
    "        self.l1_lambda, self.l2_lambda = self.args.l1_lambda_placeholder, self.args.l2_lambda_placeholder\n",
    "        self.train_y0, self.monitor_y0, self.eval_y0 = None, None, None\n",
    "        self.lr = self.args.lr\n",
    "\n",
    "    def get_ops(self):\n",
    "        \"\"\"get operators for tensorflow\"\"\"\n",
    "        if self.args.weight_loss == 'expr':\n",
    "            self.train_loss, self.train_mse_loss = loss(self.train_y, self.train_yhat, self.params['W'],\n",
    "                                                        self.l1_lambda, self.l2_lambda, weight=self.train_y)\n",
    "            self.monitor_loss, self.monitor_mse_loss = loss(self.monitor_y, self.monitor_yhat, self.params['W'],\n",
    "                                                            self.l1_lambda, self.l2_lambda, weight=self.monitor_y)\n",
    "            self.eval_loss, self.eval_mse_loss = loss(self.eval_y, self.eval_yhat, self.params['W'],\n",
    "                                                      self.l1_lambda, self.l2_lambda, weight=self.eval_y)\n",
    "        elif self.args.weight_loss == 'None':\n",
    "            self.train_loss, self.train_mse_loss = loss(self.train_y, self.train_yhat, self.params['W'],\n",
    "                                                        self.l1_lambda, self.l2_lambda)\n",
    "            self.monitor_loss, self.monitor_mse_loss = loss(self.monitor_y, self.monitor_yhat, self.params['W'],\n",
    "                                                            self.l1_lambda, self.l2_lambda)\n",
    "            self.eval_loss, self.eval_mse_loss = loss(self.eval_y, self.eval_yhat, self.params['W'],\n",
    "                                                      self.l1_lambda, self.l2_lambda)\n",
    "        \n",
    "        self.op_optimize = optimize(self.train_loss, self.lr)\n",
    "\n",
    "    def get_variables(self):\n",
    "        \"\"\"get model parameters (overwritten by model configuration)\"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def forward(self, x, mu):\n",
    "        \"\"\"forward propagation (overwritten by model configuration)\"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def build(self):\n",
    "        \"\"\"build model\"\"\"\n",
    "        self.params = {}\n",
    "        self.get_variables()\n",
    "        self.train_yhat = self.forward(self.train_y0, self.train_x)\n",
    "        self.monitor_yhat = self.forward(self.monitor_y0, self.monitor_x)\n",
    "        self.eval_yhat = self.forward(self.eval_y0, self.train_x)\n",
    "        self.get_ops()\n",
    "        return self\n",
    "\n",
    "\n",
    "class CellBox(PertBio):\n",
    "    \"\"\"CellBox model\"\"\"\n",
    "    def build(self, W_rand, inp, out):\n",
    "        self.W_rand = W_rand\n",
    "        self.inp = inp\n",
    "        self.out = out\n",
    "        self.params = {}\n",
    "        self.get_variables()\n",
    "        self.train_x = tf.constant(self.inp, name=\"sample_input\", dtype=tf.float32)\n",
    "        self.train_y = tf.constant(self.out, name=\"sample_output\", dtype=tf.float32)\n",
    "        if self.args.pert_form == 'by u':\n",
    "            y0 = tf.constant(np.zeros((self.n_x, 1)), name=\"x_init\", dtype=tf.float32)\n",
    "            self.train_y0 = y0\n",
    "            self.monitor_y0 = y0\n",
    "            self.eval_y0 = y0\n",
    "            self.gradient_zero_from = None\n",
    "        elif self.args.pert_form == 'fix x':  # fix level of node x (here y) by input perturbation u (here x)\n",
    "            self.train_y0 = tf.transpose(self.train_x)\n",
    "            self.monitor_y0 = tf.transpose(self.monitor_x)\n",
    "            self.eval_y0 = tf.transpose(self.eval_x)\n",
    "            self.gradient_zero_from = self.args.n_activity_nodes\n",
    "\n",
    "        # ODE-specific params\n",
    "        self.envelope_fn = cellbox.kernel.get_envelope(self.args)\n",
    "        self.ode_solver = cellbox.kernel.get_ode_solver(self.args)\n",
    "        self._dxdt = cellbox.kernel.get_dxdt(self.args, self.params)\n",
    "        self.convergence_metric_train, self.train_yhat = self.forward(self.train_y0, self.train_x)\n",
    "        self.convergence_metric_monitor, self.monitor_yhat = self.forward(self.monitor_y0, self.monitor_x)\n",
    "        self.convergence_metric_eval, self.eval_yhat = self.forward(self.eval_y0, self.eval_x)\n",
    "        self.get_ops()\n",
    "        return self\n",
    "\n",
    "    def forward(self, y0, mu):\n",
    "        if isinstance(mu, tf.SparseTensor):\n",
    "            mu_t = tf.sparse.to_dense(tf.sparse.transpose(mu))\n",
    "        else:\n",
    "            mu_t = tf.transpose(mu)\n",
    "        ys = self.ode_solver(y0, mu_t, self.args.dT, self.args.n_T, self._dxdt, self.gradient_zero_from)\n",
    "        # [n_T, n_x, batch_size]\n",
    "        ys = ys[-self.args.ode_last_steps:]\n",
    "        # [n_iter_tail, n_x, batch_size]\n",
    "        mean, sd = tf.nn.moments(ys, axes=0)\n",
    "        yhat = tf.transpose(ys[-1])\n",
    "        dxdt = self._dxdt(ys[-1], mu_t)\n",
    "        # [n_x, batch_size] for last ODE step\n",
    "        convergence_metric = tf.concat([mean, sd, dxdt], axis=0)\n",
    "        return convergence_metric, yhat\n",
    "\n",
    "    def get_variables(self):\n",
    "        \"\"\"\n",
    "        Initialize parameters in the Hopfield equation\n",
    "\n",
    "        Mutates:\n",
    "            self.params(dict):{\n",
    "                W (tf.Variable): interaction matrix with constraints enforced, , shape: [n_x, n_x]\n",
    "                alpha (tf.Variable): alpha, shape: [n_x, 1]\n",
    "                eps (tf.Variable): eps, shape: [n_x, 1]\n",
    "            }\n",
    "        \"\"\"\n",
    "        n_x, n_protein_nodes, n_activity_nodes = self.n_x, self.args.n_protein_nodes, self.args.n_activity_nodes\n",
    "        with tf.compat.v1.variable_scope(\"initialization\", reuse=True):\n",
    "            \"\"\"\n",
    "               Enforce constraints  (i: recipient)\n",
    "               no self regulation wii=0\n",
    "               ingoing wij for drug nodes (88th to 99th) = 0 [n_activity_nodes 87: ]\n",
    "                                w [87:99,_] = 0\n",
    "               outgoing wij for phenotypic nodes (83th to 87th) [n_protein_nodes 82 : n_activity_nodes 87]\n",
    "                                w [_, 82:87] = 0\n",
    "               ingoing wij for phenotypic nodes from drug ndoes (direct) [n_protein_nodes 82 : n_activity_nodes 87]\n",
    "                                w [82:87, 87:99] = 0\n",
    "            \"\"\"\n",
    "            #W = tf.Variable(np.random.normal(0.01, size=(n_x, n_x)), name=\"W\", dtype=tf.float32)\n",
    "            W = tf.Variable(self.W_rand, name=\"W\", dtype=tf.float32)\n",
    "            W_mask = (1.0 - np.diag(np.ones([n_x])))\n",
    "            W_mask[n_activity_nodes:, :] = np.zeros([n_x - n_activity_nodes, n_x])\n",
    "            W_mask[:, n_protein_nodes:n_activity_nodes] = np.zeros([n_x, n_activity_nodes - n_protein_nodes])\n",
    "            W_mask[n_protein_nodes:n_activity_nodes, n_activity_nodes:] = np.zeros([n_activity_nodes - n_protein_nodes,\n",
    "                                                                                    n_x - n_activity_nodes])\n",
    "            self.params['W'] = W_mask * W\n",
    "\n",
    "            eps = tf.Variable(np.ones((n_x, 1)), name=\"eps\", dtype=tf.float32)\n",
    "            alpha = tf.Variable(np.ones((n_x, 1)), name=\"alpha\", dtype=tf.float32)\n",
    "            self.params['alpha'] = tf.nn.softplus(alpha)\n",
    "            self.params['eps'] = tf.nn.softplus(eps)\n",
    "\n",
    "            if self.args.envelope == 2:\n",
    "                psi = tf.Variable(np.ones((n_x, 1)), name=\"psi\", dtype=tf.float32)\n",
    "                self.params['psi'] = tf.nn.softplus(psi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CellBox(args).build()\n",
    "lr = 0.1\n",
    "l1_lambda = 0.1\n",
    "l2_lambda = 0.01\n",
    "iterations = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-23 00:05:36.408801: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /cm/shared/apps/lsf10/10.1/linux3.10-glibc2.17-x86_64/lib:/data/weirauchlab/opt/lib:/data/weirauchlab/opt/lib64:/data/weirauchlab/local/lib:/users/ngun7t/anaconda3/envs/cellbox-3.6-2/lib/:/users/ngun7t/anaconda3/envs/cellbox-3.6-2/lib/:/users/ngun7t/anaconda3/envs/cellbox-3.6-2/lib/\n",
      "2023-08-23 00:05:36.408886: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-08-23 00:05:36.409003: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (bmiclusterp2.chmcres.cchmc.org): /proc/driver/nvidia/version does not exist\n",
      "2023-08-23 00:05:36.410629: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-08-23 00:05:36.842683: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:357] MLIR V1 optimization pass is not enabled\n"
     ]
    }
   ],
   "source": [
    "sess = tf.compat.v1.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "sess.run(model.iter_train.initializer, feed_dict=args.feed_dicts['train_set'])\n",
    "sess.run(model.iter_monitor.initializer, feed_dict=args.feed_dicts['valid_set'])\n",
    "train_input = args.iter_train.get_next()[0].eval(session=sess)\n",
    "# train_input is only a placeholder. The actual input the model uses is defined within the model's function above\n",
    "yhat = sess.run(model.train_yhat, feed_dict={args.pert_in: np.ones((4, 99)), args.expr_out: np.ones((4, 99))})\n",
    "_, loss_train_i, loss_train_mse_i = sess.run(\n",
    "                    (model.op_optimize, model.train_loss, model.train_mse_loss), \n",
    "                    feed_dict={\n",
    "                        args.pert_in: np.ones((4, 99)), \n",
    "                        args.expr_out: np.ones((4, 99)),\n",
    "                        model.lr: lr,\n",
    "                        model.l1_lambda: l1_lambda,\n",
    "                        model.l2_lambda: l2_lambda\n",
    "                        }\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8145397"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_train_mse_i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize weights for Pytorch models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelConfig(object):\n",
    "\n",
    "    def __init__(self, model, n_x, envelope_form, ode_solver, n_T):\n",
    "        self.model = model\n",
    "        self.n_x = n_x\n",
    "        self.iter_train, self.iter_monitor, self.iter_eval = None, None, None\n",
    "        self.lr = 0.1\n",
    "        self.n_protein_nodes, self.n_activity_nodes = 82, 87\n",
    "        self.pert_form = \"by u\"\n",
    "\n",
    "        self.envelope_form = envelope_form\n",
    "        self.envelope_fn = None\n",
    "        self.polynomial_k = 2\n",
    "        self.ode_degree = 1\n",
    "        self.envelope = 0\n",
    "        self.ode_solver = ode_solver\n",
    "        self.dT = 0.1\n",
    "        self.ode_last_steps = 2\n",
    "        self.n_T = n_T\n",
    "        self.gradient_zero_from = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's try to get the model from CellBox, with all the necessary configs\n",
    "\n",
    "args = ModelConfig(\"CellBox\", 99, \"tanh\", \"heun\", 100)\n",
    "torch_cellbox = cellbox.model_torch.factory(args)[0]\n",
    "\n",
    "for w in torch_cellbox.named_parameters():\n",
    "    if w[0] == \"params.W\": w[1].data = torch.tensor(W_rand, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cellbox.utils_torch import optimize, loss\n",
    "\n",
    "lr = 0.1\n",
    "l1_lambda = 0.1\n",
    "l2_lambda = 0.01\n",
    "loss_fn = loss\n",
    "\n",
    "torch_cellbox.train()\n",
    "prediction = torch_cellbox(torch.zeros((args.n_x, 1), dtype=torch.float32), torch.tensor(inp, dtype=torch.float32))\n",
    "convergence_metric, yhat = prediction\n",
    "\n",
    "for param in torch_cellbox.named_parameters():\n",
    "    if param[0] == \"params.W\":\n",
    "        param_mat = param[1]\n",
    "        break\n",
    "\n",
    "loss_train_i_torch, loss_train_mse_i_torch = loss_fn(torch.tensor(out, dtype=torch.float32), yhat, param_mat, l1=l1_lambda, l2=l2_lambda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "727.26514\n",
      "727.2650756835938\n"
     ]
    }
   ],
   "source": [
    "print(loss_train_i)\n",
    "print(loss_train_i_torch.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8145397\n",
      "0.8145418167114258\n"
     ]
    }
   ],
   "source": [
    "print(loss_train_mse_i)\n",
    "print(loss_train_mse_i_torch.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test cases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Input and output matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(89, 99)\n",
      "[13, 51, 17, 20]\n",
      "(89, 99)\n",
      "[56, 66, 52, 55]\n",
      "(89, 99)\n",
      "[55, 67, 14, 36]\n",
      "(89, 99)\n",
      "[83, 0, 25, 1]\n",
      "(89, 99)\n",
      "[26, 46, 56, 3]\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "seeds = [7, 87, 62, 45, 23]\n",
    "lambdas = [(2.0, 3.0), (0.1, 0.01), (0.001, 0.0001), (0.01, 0.1), (0.0001, 0.001)]\n",
    "others = [\n",
    "    (\"tanh\", \"heun\", 100, \"by u\"),\n",
    "    (\"tanh\", \"euler\", 100, \"by u\"),\n",
    "    (\"clip linear\", \"heun\", 100, \"fix x\"),\n",
    "    (\"tanh\", \"heun\", 100, \"fix x\"),\n",
    "    (\"tanh\", \"midpoint\", 100, \"fix x\")\n",
    "]\n",
    "\n",
    "for seed, lamb, other in zip(seeds, lambdas, others):\n",
    "    W_rand = weight_init(seed)\n",
    "    inp, out = input_init(seed)\n",
    "    data = {\n",
    "        \"seed\": seed,\n",
    "        \"W\": W_rand,\n",
    "        \"inp\": inp,\n",
    "        \"out\": out,\n",
    "        \"l1_lambda\": lamb[0],\n",
    "        \"l2_lambda\": lamb[1],\n",
    "        \"envelope_form\": other[0],\n",
    "        \"ode_solver\": other[1],\n",
    "        \"n_T\": other[2],\n",
    "        \"pert_form\": other[3]\n",
    "    }\n",
    "    with open(f\"/users/ngun7t/Documents/cellbox-jun-6/test_arrays/forward_pass/forward_input_{seed}_{lamb[0]}_{lamb[1]}.pkl\", \"wb\") as f:\n",
    "        pickle.dump(data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_args = args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on 7\n",
      "Working on 87\n",
      "Working on 62\n",
      "Working on 45\n",
      "Working on 23\n"
     ]
    }
   ],
   "source": [
    "# Build Tensorflow's models with those weights\n",
    "for seed, lamb, other in zip(seeds, lambdas, others):\n",
    "    with open(f\"/users/ngun7t/Documents/cellbox-jun-6/test_arrays/forward_pass/forward_input_{seed}_{lamb[0]}_{lamb[1]}.pkl\", \"rb\") as f:\n",
    "        data = pickle.load(f)\n",
    "\n",
    "    print(f\"Working on {seed}\")\n",
    "\n",
    "    tf_args.envelope_form = other[0]\n",
    "    tf_args.ode_solver = other[1]\n",
    "    tf_args.n_T = other[2]\n",
    "    tf_args.pert_form = other[3]\n",
    "\n",
    "    W_rand, l1_lambda, l2_lambda, inp, out = data[\"W\"], data[\"l1_lambda\"], data[\"l2_lambda\"], data[\"inp\"], data[\"out\"]\n",
    "    lr = 0.1\n",
    "    model = CellBox(tf_args).build(W_rand, inp, out)\n",
    "    sess = tf.compat.v1.Session()\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    sess.run(model.iter_train.initializer, feed_dict=tf_args.feed_dicts['train_set'])\n",
    "    sess.run(model.iter_monitor.initializer, feed_dict=tf_args.feed_dicts['valid_set'])\n",
    "    train_input = tf_args.iter_train.get_next()[0].eval(session=sess)\n",
    "    yhat = sess.run(model.train_yhat, feed_dict={tf_args.pert_in: np.ones((4, 99)), tf_args.expr_out: np.ones((4, 99))})\n",
    "    _, loss_train_i, loss_train_mse_i = sess.run(\n",
    "                        (model.op_optimize, model.train_loss, model.train_mse_loss), \n",
    "                        feed_dict={\n",
    "                            tf_args.pert_in: np.ones((4, 99)), \n",
    "                            tf_args.expr_out: np.ones((4, 99)),\n",
    "                            model.lr: lr,\n",
    "                            model.l1_lambda: l1_lambda,\n",
    "                            model.l2_lambda: l2_lambda\n",
    "                            }\n",
    "                        )\n",
    "\n",
    "    tf_out = {\n",
    "        \"yhat\": yhat,\n",
    "        \"loss_train\": loss_train_i,\n",
    "        \"loss_train_mse\": loss_train_mse_i\n",
    "    }\n",
    "    with open(f\"/users/ngun7t/Documents/cellbox-jun-6/test_arrays/forward_pass/forward_out_{seed}_{l1_lambda}_{l2_lambda}.pkl\", \"wb\") as f:\n",
    "        pickle.dump(tf_out, f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Validate this on Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelConfig(object):\n",
    "\n",
    "    def __init__(self, model, n_x, envelope_form, ode_solver, n_T):\n",
    "        self.model = model\n",
    "        self.n_x = n_x\n",
    "        self.iter_train, self.iter_monitor, self.iter_eval = None, None, None\n",
    "        self.lr = 0.1\n",
    "        self.n_protein_nodes, self.n_activity_nodes = 82, 87\n",
    "        self.pert_form = \"by u\"\n",
    "\n",
    "        self.envelope_form = envelope_form\n",
    "        self.envelope_fn = None\n",
    "        self.polynomial_k = 2\n",
    "        self.ode_degree = 1\n",
    "        self.envelope = 0\n",
    "        self.ode_solver = ode_solver\n",
    "        self.dT = 0.1\n",
    "        self.ode_last_steps = 2\n",
    "        self.n_T = n_T\n",
    "        self.gradient_zero_from = None\n",
    "\n",
    "torch_args = ModelConfig(\"CellBox\", 99, \"tanh\", \"heun\", 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on seed=7\n",
      ">>> TF: 36551.5, Torch: 36551.5\n",
      ">>> TF: 0.8670288920402527, Torch: 0.867030143737793\n",
      ">>> Prediction similar: True\n",
      "Working on seed=87\n",
      ">>> TF: 726.19677734375, Torch: 726.19677734375\n",
      ">>> TF: 0.8856361508369446, Torch: 0.8856316208839417\n",
      ">>> Prediction similar: False\n",
      "Working on seed=62\n",
      ">>> TF: 8.151704788208008, Torch: 8.151703834533691\n",
      ">>> TF: 0.8972810506820679, Torch: 0.8972810506820679\n",
      ">>> Prediction similar: True\n",
      "Working on seed=45\n",
      ">>> TF: 863.7166137695312, Torch: 863.7166748046875\n",
      ">>> TF: 0.7445549368858337, Torch: 0.7445532083511353\n",
      ">>> Prediction similar: True\n",
      "Working on seed=23\n",
      ">>> TF: 9.63156795501709, Torch: 9.631569862365723\n",
      ">>> TF: 0.8667668104171753, Torch: 0.8667678236961365\n",
      ">>> Prediction similar: True\n"
     ]
    }
   ],
   "source": [
    "yhat_diff = 0.01\n",
    "\n",
    "for seed, lamb, other in zip(seeds, lambdas, others):\n",
    "    print(f\"Working on {seed=}\")\n",
    "    with open(f\"/users/ngun7t/Documents/cellbox-jun-6/test_arrays/forward_pass/forward_input_{seed}_{lamb[0]}_{lamb[1]}.pkl\", \"rb\") as f:\n",
    "        data = pickle.load(f)\n",
    "    with open(f\"/users/ngun7t/Documents/cellbox-jun-6/test_arrays/forward_pass/forward_out_{seed}_{lamb[0]}_{lamb[1]}.pkl\", \"rb\") as f:\n",
    "        data_out = pickle.load(f)\n",
    "\n",
    "    torch_args.envelope_form = other[0]\n",
    "    torch_args.ode_solver = other[1]\n",
    "    torch_args.n_T = other[2]\n",
    "    torch_args.pert_form = other[3]\n",
    "    torch_cellbox = cellbox.model_torch.factory(torch_args)[0]\n",
    "    \n",
    "\n",
    "    for w in torch_cellbox.named_parameters():\n",
    "        if w[0] == \"params.W\": w[1].data = torch.tensor(data[\"W\"], dtype=torch.float32)\n",
    "\n",
    "    l1_lambda = data[\"l1_lambda\"]\n",
    "    l2_lambda = data[\"l2_lambda\"]\n",
    "    loss_fn = cellbox.utils_torch.loss\n",
    "\n",
    "    torch_cellbox.train()\n",
    "    if torch_args.pert_form == \"by u\":\n",
    "        prediction = torch_cellbox(torch.zeros((torch_args.n_x, 1), dtype=torch.float32), torch.tensor(data[\"inp\"], dtype=torch.float32))\n",
    "    elif torch_args.pert_form == \"fix x\":\n",
    "        prediction = torch_cellbox(\n",
    "            torch.tensor(data[\"inp\"].T, dtype=torch.float32),\n",
    "            torch.tensor(data[\"inp\"], dtype=torch.float32)\n",
    "        )\n",
    "    #prediction = torch_cellbox(torch.zeros((args.n_x, 1), dtype=torch.float32), torch.tensor(data[\"inp\"], dtype=torch.float32))\n",
    "    convergence_metric, yhat = prediction\n",
    "\n",
    "    for param in torch_cellbox.named_parameters():\n",
    "        if param[0] == \"params.W\":\n",
    "            param_mat = param[1]\n",
    "            break\n",
    "\n",
    "    loss_train_i_torch, loss_train_mse_i_torch = loss_fn(torch.tensor(data[\"out\"], dtype=torch.float32), yhat, param_mat, l1=l1_lambda, l2=l2_lambda)\n",
    "    print(f\">>> TF: {data_out['loss_train']}, Torch: {loss_train_i_torch.item()}\")\n",
    "    print(f\">>> TF: {data_out['loss_train_mse']}, Torch: {loss_train_mse_i_torch.item()}\")\n",
    "    print(f\">>> Prediction similar: {np.all(np.abs(data_out['yhat'] - yhat.detach().cpu().numpy()) < yhat_diff)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cellbox-3.6-2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
