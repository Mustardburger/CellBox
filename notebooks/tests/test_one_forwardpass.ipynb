{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-22 23:10:14.880216: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-08-22 23:10:19.858227: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-08-22 23:10:20.347393: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /cm/shared/apps/lsf10/10.1/linux3.10-glibc2.17-x86_64/lib:/data/weirauchlab/opt/lib:/data/weirauchlab/opt/lib64:/data/weirauchlab/local/lib:/users/ngun7t/anaconda3/envs/cellbox-3.6-2/lib/:/users/ngun7t/anaconda3/envs/cellbox-3.6-2/lib/:/users/ngun7t/anaconda3/envs/cellbox-3.6-2/lib/\n",
      "2023-08-22 23:10:20.347449: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-08-22 23:10:41.045211: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /cm/shared/apps/lsf10/10.1/linux3.10-glibc2.17-x86_64/lib:/data/weirauchlab/opt/lib:/data/weirauchlab/opt/lib64:/data/weirauchlab/local/lib:/users/ngun7t/anaconda3/envs/cellbox-3.6-2/lib/:/users/ngun7t/anaconda3/envs/cellbox-3.6-2/lib/:/users/ngun7t/anaconda3/envs/cellbox-3.6-2/lib/\n",
      "2023-08-22 23:10:41.046831: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /cm/shared/apps/lsf10/10.1/linux3.10-glibc2.17-x86_64/lib:/data/weirauchlab/opt/lib:/data/weirauchlab/opt/lib64:/data/weirauchlab/local/lib:/users/ngun7t/anaconda3/envs/cellbox-3.6-2/lib/:/users/ngun7t/anaconda3/envs/cellbox-3.6-2/lib/:/users/ngun7t/anaconda3/envs/cellbox-3.6-2/lib/\n",
      "2023-08-22 23:10:41.046863: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /users/ngun7t/anaconda3/envs/cellbox-3.6-2/lib/python3.8/site-packages/tensorflow/python/compat/v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n",
      "================================================================================\n",
      "   _____     _ _ ____              \n",
      "  / ____|   | | |  _ \\             \n",
      " | |     ___| | | |_) | _____  __  \n",
      " | |    / _ \\ | |  _ < / _ \\ \\/ /  \n",
      " | |___|  __/ | | |_) | (_) >  <   \n",
      "  \\_____\\___|_|_|____/ \\___/_/\\_\\  \n",
      "Running CellBox scripts developed in Sander lab\n",
      "Maintained by Bo Yuan, Judy Shen, and Augustin Luna; contributions by Daniel Ritter\n",
      "\n",
      "        version 0.3.2\n",
      "        -- Feb 10, 2023 --\n",
      "        * Modify CellBox to support TF2     \n",
      "        \n",
      "Tutorials and documentations are available at https://github.com/sanderlab/CellBox\n",
      "If you want to discuss the usage or to report a bug, please use the 'Issues' function at GitHub.\n",
      "If you find CellBox useful for your research, please consider citing the corresponding publication.\n",
      "For more information, please email us at boyuan@g.harvard.edu and c_shen@g.harvard.edu, augustin_luna@hms.harvard.edu\n",
      " --------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import cellbox\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow.compat.v1 as tf\n",
    "import shutil\n",
    "import argparse\n",
    "import json\n",
    "import glob\n",
    "import time\n",
    "from tensorflow.compat.v1.errors import OutOfRangeError\n",
    "from cellbox.utils import TimeLogger\n",
    "tf.disable_v2_behavior()\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize weights with correct masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_init(seed, n_x=99, n_protein_nodes=82, n_activity_nodes=87):\n",
    "    np.random.seed(seed)\n",
    "    W = np.random.normal(0.01, 1.0, size=(n_x, n_x))\n",
    "    W_mask = (1.0 - np.diag(np.ones([n_x])))\n",
    "    W_mask[n_activity_nodes:, :] = np.zeros([n_x - n_activity_nodes, n_x])\n",
    "    W_mask[:, n_protein_nodes:n_activity_nodes] = np.zeros([n_x, n_activity_nodes - n_protein_nodes])\n",
    "    W_mask[n_protein_nodes:n_activity_nodes, n_activity_nodes:] = np.zeros([n_activity_nodes - n_protein_nodes,\n",
    "                                                                            n_x - n_activity_nodes])\n",
    "\n",
    "    return W*W_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 99)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.zeros((89, 99))\n",
    "b = a[[1, 3, 5]]\n",
    "b.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize input matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_init(seed):\n",
    "    # Initialize the input by taking a slice of the actual input\n",
    "    np.random.seed(seed)\n",
    "    real_inp = pd.read_csv(\"/users/ngun7t/Documents/cellbox-jun-6/data/pert.csv\", header=None).to_numpy()\n",
    "    real_out = pd.read_csv(\"/users/ngun7t/Documents/cellbox-jun-6/data/expr.csv\", header=None).to_numpy()\n",
    "    rand_ind = np.random.choice(list(range(89)), replace=False, size=(4,)).tolist()\n",
    "    inp = real_inp[rand_ind]\n",
    "    out = real_out[rand_ind]\n",
    "    return inp, out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(89, 99)\n",
      "[44, 53, 30, 12]\n"
     ]
    }
   ],
   "source": [
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "tf.compat.v1.set_random_seed(seed)\n",
    "\n",
    "W_rand = weight_init(seed)\n",
    "inp, out = input_init(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make tensorflow model, initialize the weights, and make a forward pass with this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'experiment_id': 'Example_RP', 'model_prefix': 'seed', 'ckpt_name': 'model11.ckpt', 'export_verbose': 3, 'experiment_type': 'random partition', 'sparse_data': False, 'batchsize': 4, 'trainset_ratio': 0.7, 'validset_ratio': 0.8, 'n_batches_eval': None, 'add_noise_level': 0, 'dT': 0.1, 'ode_solver': 'heun', 'envelope_form': 'tanh', 'envelope': 0, 'pert_form': 'by u', 'ode_degree': 1, 'ode_last_steps': 2, 'n_iter_buffer': 50, 'n_iter_patience': 100, 'weight_loss': 'None', 'l1lambda': 0.0001, 'l2lambda': 0.0001, 'model': 'CellBox', 'pert_file': '/users/ngun7t/Documents/cellbox-jun-6/data/pert.csv', 'expr_file': '/users/ngun7t/Documents/cellbox-jun-6/data/expr.csv', 'node_index_file': '/users/ngun7t/Documents/cellbox-jun-6/data/node_Index.csv', 'n_protein_nodes': 82, 'n_activity_nodes': 87, 'n_x': 99, 'envelop_form': 'tanh', 'envelop': 0, 'n_epoch': 100, 'n_iter': 100, 'stages': [{'nT': 100, 'sub_stages': [{'lr_val': 0.1, 'l1lambda': 0.01, 'n_iter_patience': 1000}, {'lr_val': 0.01, 'l1lambda': 0.01}, {'lr_val': 0.01, 'l1lambda': 0.0001}, {'lr_val': 0.001, 'l1lambda': 1e-05}]}], 'ckpt_path_full': './model11.ckpt', 'drug_index': 5, 'seed': 7}\n",
      "Working directory is ready at results/Example_RP_370705d3fa02832e2d75733a602382b0.\n"
     ]
    }
   ],
   "source": [
    "def set_seed(in_seed):\n",
    "    int_seed = int(in_seed)\n",
    "    tf.compat.v1.set_random_seed(int_seed)\n",
    "    np.random.seed(int_seed)\n",
    "\n",
    "\n",
    "def prepare_workdir(in_cfg):\n",
    "    # Read Data\n",
    "    in_cfg.root_dir = os.getcwd()\n",
    "    in_cfg.node_index = pd.read_csv(in_cfg.node_index_file, header=None, names=None) \\\n",
    "        if hasattr(in_cfg, 'node_index_file') else pd.DataFrame(np.arange(in_cfg.n_x))\n",
    "\n",
    "    # Create Output Folder\n",
    "    experiment_path = 'results/{}_{}'.format(in_cfg.experiment_id, md5)\n",
    "    try:\n",
    "        os.makedirs(experiment_path)\n",
    "    except Exception:\n",
    "        pass\n",
    "    out_cfg = vars(in_cfg)\n",
    "    out_cfg = {key: out_cfg[key] for key in out_cfg if type(out_cfg[key]) is not pd.DataFrame}\n",
    "    os.chdir(experiment_path)\n",
    "    json.dump(out_cfg, open('config.json', 'w'), indent=4)\n",
    "\n",
    "    if \"leave one out\" in in_cfg.experiment_type:\n",
    "        try:\n",
    "            in_cfg.model_prefix = '{}_{}'.format(in_cfg.model_prefix, in_cfg.drug_index)\n",
    "        except Exception('Drug index not specified') as e:\n",
    "            raise e\n",
    "\n",
    "    in_cfg.working_index = in_cfg.model_prefix + \"_\" + str(working_index).zfill(3)\n",
    "\n",
    "    try:\n",
    "        shutil.rmtree(in_cfg.working_index)\n",
    "    except Exception:\n",
    "        pass\n",
    "    os.makedirs(in_cfg.working_index)\n",
    "    os.chdir(in_cfg.working_index)\n",
    "\n",
    "    with open(\"record_eval.csv\", 'w') as f:\n",
    "        f.write(\"epoch,iter,train_loss,valid_loss,train_mse,valid_mse,test_mse,time_elapsed\\n\")\n",
    "\n",
    "    print('Working directory is ready at {}.'.format(experiment_path))\n",
    "    return 0\n",
    "\n",
    "experiment_config_path = \"/users/ngun7t/Documents/cellbox-jun-6/configs_dev/Example.random_partition.CellBox.json\"\n",
    "working_index = 0\n",
    "stage = {\n",
    "    \"nT\": 100,\n",
    "    \"sub_stages\":[\n",
    "        {\"lr_val\": 0.1,\"l1lambda\": 0.01, \"n_iter_patience\":1000},\n",
    "        {\"lr_val\": 0.01,\"l1lambda\": 0.01},\n",
    "        {\"lr_val\": 0.01,\"l1lambda\": 0.0001},\n",
    "        {\"lr_val\": 0.001,\"l1lambda\": 0.00001}\n",
    "    ]}\n",
    "\n",
    "cfg = cellbox.config.Config(experiment_config_path)\n",
    "cfg.ckpt_path_full = os.path.join('./', cfg.ckpt_name)\n",
    "md5 = cellbox.utils.md5(cfg)\n",
    "cfg.drug_index = 5         # Change this for testing purposes\n",
    "cfg.seed = seed\n",
    "set_seed(seed)\n",
    "print(vars(cfg))\n",
    "\n",
    "prepare_workdir(cfg)\n",
    "logger = cellbox.utils.TimeLogger(time_logger_step=1, hierachy=3)\n",
    "args = cfg\n",
    "for i, stage in enumerate(cfg.stages):\n",
    "    set_seed(cfg.seed)\n",
    "    cfg = cellbox.dataset.factory(cfg)\n",
    "    args.sub_stages = stage['sub_stages']\n",
    "    args.n_T = stage['nT']\n",
    "    model = cellbox.model.factory(args)\n",
    "    if i == 0: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(89,)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cellbox.utils import loss, optimize\n",
    "\n",
    "class PertBio:\n",
    "    \"\"\"define abstract perturbation model\"\"\"\n",
    "    def __init__(self, args):\n",
    "        self.args = args\n",
    "        self.n_x = args.n_x\n",
    "        self.pert_in, self.expr_out = args.pert_in, args.expr_out\n",
    "        self.iter_train, self.iter_monitor, self.iter_eval = args.iter_train, args.iter_monitor, args.iter_eval\n",
    "        self.train_x, self.train_y = self.iter_train.get_next()\n",
    "        self.monitor_x, self.monitor_y = self.iter_monitor.get_next()\n",
    "        self.eval_x, self.eval_y = self.iter_eval.get_next()\n",
    "        self.l1_lambda, self.l2_lambda = self.args.l1_lambda_placeholder, self.args.l2_lambda_placeholder\n",
    "        self.train_y0, self.monitor_y0, self.eval_y0 = None, None, None\n",
    "        self.lr = self.args.lr\n",
    "\n",
    "    def get_ops(self):\n",
    "        \"\"\"get operators for tensorflow\"\"\"\n",
    "        if self.args.weight_loss == 'expr':\n",
    "            self.train_loss, self.train_mse_loss = loss(self.train_y, self.train_yhat, self.params['W'],\n",
    "                                                        self.l1_lambda, self.l2_lambda, weight=self.train_y)\n",
    "            self.monitor_loss, self.monitor_mse_loss = loss(self.monitor_y, self.monitor_yhat, self.params['W'],\n",
    "                                                            self.l1_lambda, self.l2_lambda, weight=self.monitor_y)\n",
    "            self.eval_loss, self.eval_mse_loss = loss(self.eval_y, self.eval_yhat, self.params['W'],\n",
    "                                                      self.l1_lambda, self.l2_lambda, weight=self.eval_y)\n",
    "        elif self.args.weight_loss == 'None':\n",
    "            self.train_loss, self.train_mse_loss = loss(self.train_y, self.train_yhat, self.params['W'],\n",
    "                                                        self.l1_lambda, self.l2_lambda)\n",
    "            self.monitor_loss, self.monitor_mse_loss = loss(self.monitor_y, self.monitor_yhat, self.params['W'],\n",
    "                                                            self.l1_lambda, self.l2_lambda)\n",
    "            self.eval_loss, self.eval_mse_loss = loss(self.eval_y, self.eval_yhat, self.params['W'],\n",
    "                                                      self.l1_lambda, self.l2_lambda)\n",
    "        \n",
    "        self.op_optimize = optimize(self.train_loss, self.lr)\n",
    "\n",
    "    def get_variables(self):\n",
    "        \"\"\"get model parameters (overwritten by model configuration)\"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def forward(self, x, mu):\n",
    "        \"\"\"forward propagation (overwritten by model configuration)\"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def build(self):\n",
    "        \"\"\"build model\"\"\"\n",
    "        self.params = {}\n",
    "        self.get_variables()\n",
    "        self.train_yhat = self.forward(self.train_y0, self.train_x)\n",
    "        self.monitor_yhat = self.forward(self.monitor_y0, self.monitor_x)\n",
    "        self.eval_yhat = self.forward(self.eval_y0, self.train_x)\n",
    "        self.get_ops()\n",
    "        return self\n",
    "\n",
    "\n",
    "class CellBox(PertBio):\n",
    "    \"\"\"CellBox model\"\"\"\n",
    "    def build(self, W_rand, inp, out):\n",
    "        self.W_rand = W_rand\n",
    "        self.inp = inp\n",
    "        self.out = out\n",
    "        self.params = {}\n",
    "        self.get_variables()\n",
    "        self.train_x = tf.constant(self.inp, name=\"sample_input\", dtype=tf.float32)\n",
    "        self.train_y = tf.constant(self.out, name=\"sample_output\", dtype=tf.float32)\n",
    "        if self.args.pert_form == 'by u':\n",
    "            y0 = tf.constant(np.zeros((self.n_x, 1)), name=\"x_init\", dtype=tf.float32)\n",
    "            self.train_y0 = y0\n",
    "            self.monitor_y0 = y0\n",
    "            self.eval_y0 = y0\n",
    "            self.gradient_zero_from = None\n",
    "        elif self.args.pert_form == 'fix x':  # fix level of node x (here y) by input perturbation u (here x)\n",
    "            self.train_y0 = tf.transpose(self.train_x)\n",
    "            self.monitor_y0 = tf.transpose(self.monitor_x)\n",
    "            self.eval_y0 = tf.transpose(self.eval_x)\n",
    "            self.gradient_zero_from = self.args.n_activity_nodes\n",
    "\n",
    "        # ODE-specific params\n",
    "        self.envelope_fn = cellbox.kernel.get_envelope(self.args)\n",
    "        self.ode_solver = cellbox.kernel.get_ode_solver(self.args)\n",
    "        self._dxdt = cellbox.kernel.get_dxdt(self.args, self.params)\n",
    "        self.convergence_metric_train, self.train_yhat = self.forward(self.train_y0, self.train_x)\n",
    "        self.convergence_metric_monitor, self.monitor_yhat = self.forward(self.monitor_y0, self.monitor_x)\n",
    "        self.convergence_metric_eval, self.eval_yhat = self.forward(self.eval_y0, self.eval_x)\n",
    "        self.get_ops()\n",
    "        return self\n",
    "\n",
    "    def forward(self, y0, mu):\n",
    "        if isinstance(mu, tf.SparseTensor):\n",
    "            mu_t = tf.sparse.to_dense(tf.sparse.transpose(mu))\n",
    "        else:\n",
    "            mu_t = tf.transpose(mu)\n",
    "        ys = self.ode_solver(y0, mu_t, self.args.dT, self.args.n_T, self._dxdt, self.gradient_zero_from)\n",
    "        # [n_T, n_x, batch_size]\n",
    "        ys = ys[-self.args.ode_last_steps:]\n",
    "        # [n_iter_tail, n_x, batch_size]\n",
    "        mean, sd = tf.nn.moments(ys, axes=0)\n",
    "        yhat = tf.transpose(ys[-1])\n",
    "        dxdt = self._dxdt(ys[-1], mu_t)\n",
    "        # [n_x, batch_size] for last ODE step\n",
    "        convergence_metric = tf.concat([mean, sd, dxdt], axis=0)\n",
    "        return convergence_metric, yhat\n",
    "\n",
    "    def get_variables(self):\n",
    "        \"\"\"\n",
    "        Initialize parameters in the Hopfield equation\n",
    "\n",
    "        Mutates:\n",
    "            self.params(dict):{\n",
    "                W (tf.Variable): interaction matrix with constraints enforced, , shape: [n_x, n_x]\n",
    "                alpha (tf.Variable): alpha, shape: [n_x, 1]\n",
    "                eps (tf.Variable): eps, shape: [n_x, 1]\n",
    "            }\n",
    "        \"\"\"\n",
    "        n_x, n_protein_nodes, n_activity_nodes = self.n_x, self.args.n_protein_nodes, self.args.n_activity_nodes\n",
    "        with tf.compat.v1.variable_scope(\"initialization\", reuse=True):\n",
    "            \"\"\"\n",
    "               Enforce constraints  (i: recipient)\n",
    "               no self regulation wii=0\n",
    "               ingoing wij for drug nodes (88th to 99th) = 0 [n_activity_nodes 87: ]\n",
    "                                w [87:99,_] = 0\n",
    "               outgoing wij for phenotypic nodes (83th to 87th) [n_protein_nodes 82 : n_activity_nodes 87]\n",
    "                                w [_, 82:87] = 0\n",
    "               ingoing wij for phenotypic nodes from drug ndoes (direct) [n_protein_nodes 82 : n_activity_nodes 87]\n",
    "                                w [82:87, 87:99] = 0\n",
    "            \"\"\"\n",
    "            #W = tf.Variable(np.random.normal(0.01, size=(n_x, n_x)), name=\"W\", dtype=tf.float32)\n",
    "            W = tf.Variable(self.W_rand, name=\"W\", dtype=tf.float32)\n",
    "            W_mask = (1.0 - np.diag(np.ones([n_x])))\n",
    "            W_mask[n_activity_nodes:, :] = np.zeros([n_x - n_activity_nodes, n_x])\n",
    "            W_mask[:, n_protein_nodes:n_activity_nodes] = np.zeros([n_x, n_activity_nodes - n_protein_nodes])\n",
    "            W_mask[n_protein_nodes:n_activity_nodes, n_activity_nodes:] = np.zeros([n_activity_nodes - n_protein_nodes,\n",
    "                                                                                    n_x - n_activity_nodes])\n",
    "            self.params['W'] = W_mask * W\n",
    "\n",
    "            eps = tf.Variable(np.ones((n_x, 1)), name=\"eps\", dtype=tf.float32)\n",
    "            alpha = tf.Variable(np.ones((n_x, 1)), name=\"alpha\", dtype=tf.float32)\n",
    "            self.params['alpha'] = tf.nn.softplus(alpha)\n",
    "            self.params['eps'] = tf.nn.softplus(eps)\n",
    "\n",
    "            if self.args.envelope == 2:\n",
    "                psi = tf.Variable(np.ones((n_x, 1)), name=\"psi\", dtype=tf.float32)\n",
    "                self.params['psi'] = tf.nn.softplus(psi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CellBox(args).build()\n",
    "lr = 0.1\n",
    "l1_lambda = 0.1\n",
    "l2_lambda = 0.01\n",
    "iterations = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-23 00:05:36.408801: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /cm/shared/apps/lsf10/10.1/linux3.10-glibc2.17-x86_64/lib:/data/weirauchlab/opt/lib:/data/weirauchlab/opt/lib64:/data/weirauchlab/local/lib:/users/ngun7t/anaconda3/envs/cellbox-3.6-2/lib/:/users/ngun7t/anaconda3/envs/cellbox-3.6-2/lib/:/users/ngun7t/anaconda3/envs/cellbox-3.6-2/lib/\n",
      "2023-08-23 00:05:36.408886: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-08-23 00:05:36.409003: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (bmiclusterp2.chmcres.cchmc.org): /proc/driver/nvidia/version does not exist\n",
      "2023-08-23 00:05:36.410629: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-08-23 00:05:36.842683: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:357] MLIR V1 optimization pass is not enabled\n"
     ]
    }
   ],
   "source": [
    "sess = tf.compat.v1.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "sess.run(model.iter_train.initializer, feed_dict=args.feed_dicts['train_set'])\n",
    "sess.run(model.iter_monitor.initializer, feed_dict=args.feed_dicts['valid_set'])\n",
    "train_input = args.iter_train.get_next()[0].eval(session=sess)\n",
    "# train_input is only a placeholder. The actual input the model uses is defined within the model's function above\n",
    "yhat = sess.run(model.train_yhat, feed_dict={args.pert_in: np.ones((4, 99)), args.expr_out: np.ones((4, 99))})\n",
    "_, loss_train_i, loss_train_mse_i = sess.run(\n",
    "                    (model.op_optimize, model.train_loss, model.train_mse_loss), \n",
    "                    feed_dict={\n",
    "                        args.pert_in: np.ones((4, 99)), \n",
    "                        args.expr_out: np.ones((4, 99)),\n",
    "                        model.lr: lr,\n",
    "                        model.l1_lambda: l1_lambda,\n",
    "                        model.l2_lambda: l2_lambda\n",
    "                        }\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8145397"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_train_mse_i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize weights for Pytorch models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelConfig(object):\n",
    "\n",
    "    def __init__(self, model, n_x, envelope_form, ode_solver, n_T):\n",
    "        self.model = model\n",
    "        self.n_x = n_x\n",
    "        self.iter_train, self.iter_monitor, self.iter_eval = None, None, None\n",
    "        self.lr = 0.1\n",
    "        self.n_protein_nodes, self.n_activity_nodes = 82, 87\n",
    "        self.pert_form = \"by u\"\n",
    "\n",
    "        self.envelope_form = envelope_form\n",
    "        self.envelope_fn = None\n",
    "        self.polynomial_k = 2\n",
    "        self.ode_degree = 1\n",
    "        self.envelope = 0\n",
    "        self.ode_solver = ode_solver\n",
    "        self.dT = 0.1\n",
    "        self.ode_last_steps = 2\n",
    "        self.n_T = n_T\n",
    "        self.gradient_zero_from = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's try to get the model from CellBox, with all the necessary configs\n",
    "\n",
    "args = ModelConfig(\"CellBox\", 99, \"tanh\", \"heun\", 100)\n",
    "torch_cellbox = cellbox.model_torch.factory(args)[0]\n",
    "\n",
    "for w in torch_cellbox.named_parameters():\n",
    "    if w[0] == \"params.W\": w[1].data = torch.tensor(W_rand, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cellbox.utils_torch import optimize, loss\n",
    "\n",
    "lr = 0.1\n",
    "l1_lambda = 0.1\n",
    "l2_lambda = 0.01\n",
    "loss_fn = loss\n",
    "\n",
    "torch_cellbox.train()\n",
    "prediction = torch_cellbox(torch.zeros((args.n_x, 1), dtype=torch.float32), torch.tensor(inp, dtype=torch.float32))\n",
    "convergence_metric, yhat = prediction\n",
    "\n",
    "for param in torch_cellbox.named_parameters():\n",
    "    if param[0] == \"params.W\":\n",
    "        param_mat = param[1]\n",
    "        break\n",
    "\n",
    "loss_train_i_torch, loss_train_mse_i_torch = loss_fn(torch.tensor(out, dtype=torch.float32), yhat, param_mat, l1=l1_lambda, l2=l2_lambda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "727.26514\n",
      "727.2650756835938\n"
     ]
    }
   ],
   "source": [
    "print(loss_train_i)\n",
    "print(loss_train_i_torch.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8145397\n",
      "0.8145418167114258\n"
     ]
    }
   ],
   "source": [
    "print(loss_train_mse_i)\n",
    "print(loss_train_mse_i_torch.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test cases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Input and output matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(89, 99)\n",
      "[13, 51, 17, 20]\n",
      "(89, 99)\n",
      "[56, 66, 52, 55]\n",
      "(89, 99)\n",
      "[55, 67, 14, 36]\n",
      "(89, 99)\n",
      "[83, 0, 25, 1]\n",
      "(89, 99)\n",
      "[26, 46, 56, 3]\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "seeds = [7, 87, 62, 45, 23]\n",
    "lambdas = [(2.0, 3.0), (0.1, 0.01), (0.001, 0.0001), (0.01, 0.1), (0.0001, 0.001)]\n",
    "others = [\n",
    "    (\"tanh\", \"heun\", 100, \"by u\"),\n",
    "    (\"tanh\", \"euler\", 100, \"by u\"),\n",
    "    (\"clip linear\", \"heun\", 100, \"fix x\"),\n",
    "    (\"tanh\", \"heun\", 100, \"fix x\"),\n",
    "    (\"tanh\", \"midpoint\", 100, \"fix x\")\n",
    "]\n",
    "\n",
    "for seed, lamb, other in zip(seeds, lambdas, others):\n",
    "    W_rand = weight_init(seed)\n",
    "    inp, out = input_init(seed)\n",
    "    data = {\n",
    "        \"seed\": seed,\n",
    "        \"W\": W_rand,\n",
    "        \"inp\": inp,\n",
    "        \"out\": out,\n",
    "        \"l1_lambda\": lamb[0],\n",
    "        \"l2_lambda\": lamb[1],\n",
    "        \"envelope_form\": other[0],\n",
    "        \"ode_solver\": other[1],\n",
    "        \"n_T\": other[2],\n",
    "        \"pert_form\": other[3]\n",
    "    }\n",
    "    with open(f\"/users/ngun7t/Documents/cellbox-jun-6/test_arrays/forward_pass/forward_input_{seed}_{lamb[0]}_{lamb[1]}.pkl\", \"wb\") as f:\n",
    "        pickle.dump(data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_args = args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on 7\n",
      "Working on 87\n",
      "Working on 62\n",
      "Working on 45\n",
      "Working on 23\n"
     ]
    }
   ],
   "source": [
    "# Build Tensorflow's models with those weights\n",
    "for seed, lamb, other in zip(seeds, lambdas, others):\n",
    "    with open(f\"/users/ngun7t/Documents/cellbox-jun-6/test_arrays/forward_pass/forward_input_{seed}_{lamb[0]}_{lamb[1]}.pkl\", \"rb\") as f:\n",
    "        data = pickle.load(f)\n",
    "\n",
    "    print(f\"Working on {seed}\")\n",
    "\n",
    "    tf_args.envelope_form = other[0]\n",
    "    tf_args.ode_solver = other[1]\n",
    "    tf_args.n_T = other[2]\n",
    "    tf_args.pert_form = other[3]\n",
    "\n",
    "    W_rand, l1_lambda, l2_lambda, inp, out = data[\"W\"], data[\"l1_lambda\"], data[\"l2_lambda\"], data[\"inp\"], data[\"out\"]\n",
    "    lr = 0.1\n",
    "    model = CellBox(tf_args).build(W_rand, inp, out)\n",
    "    sess = tf.compat.v1.Session()\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    sess.run(model.iter_train.initializer, feed_dict=tf_args.feed_dicts['train_set'])\n",
    "    sess.run(model.iter_monitor.initializer, feed_dict=tf_args.feed_dicts['valid_set'])\n",
    "    train_input = tf_args.iter_train.get_next()[0].eval(session=sess)\n",
    "    yhat = sess.run(model.train_yhat, feed_dict={tf_args.pert_in: np.ones((4, 99)), tf_args.expr_out: np.ones((4, 99))})\n",
    "    _, loss_train_i, loss_train_mse_i = sess.run(\n",
    "                        (model.op_optimize, model.train_loss, model.train_mse_loss), \n",
    "                        feed_dict={\n",
    "                            tf_args.pert_in: np.ones((4, 99)), \n",
    "                            tf_args.expr_out: np.ones((4, 99)),\n",
    "                            model.lr: lr,\n",
    "                            model.l1_lambda: l1_lambda,\n",
    "                            model.l2_lambda: l2_lambda\n",
    "                            }\n",
    "                        )\n",
    "\n",
    "    tf_out = {\n",
    "        \"yhat\": yhat,\n",
    "        \"loss_train\": loss_train_i,\n",
    "        \"loss_train_mse\": loss_train_mse_i\n",
    "    }\n",
    "    with open(f\"/users/ngun7t/Documents/cellbox-jun-6/test_arrays/forward_pass/forward_out_{seed}_{l1_lambda}_{l2_lambda}.pkl\", \"wb\") as f:\n",
    "        pickle.dump(tf_out, f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Validate this on Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelConfig(object):\n",
    "\n",
    "    def __init__(self, model, n_x, envelope_form, ode_solver, n_T):\n",
    "        self.model = model\n",
    "        self.n_x = n_x\n",
    "        self.iter_train, self.iter_monitor, self.iter_eval = None, None, None\n",
    "        self.lr = 0.1\n",
    "        self.n_protein_nodes, self.n_activity_nodes = 82, 87\n",
    "        self.pert_form = \"by u\"\n",
    "\n",
    "        self.envelope_form = envelope_form\n",
    "        self.envelope_fn = None\n",
    "        self.polynomial_k = 2\n",
    "        self.ode_degree = 1\n",
    "        self.envelope = 0\n",
    "        self.ode_solver = ode_solver\n",
    "        self.dT = 0.1\n",
    "        self.ode_last_steps = 2\n",
    "        self.n_T = n_T\n",
    "        self.gradient_zero_from = None\n",
    "\n",
    "torch_args = ModelConfig(\"CellBox\", 99, \"tanh\", \"heun\", 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on seed=7\n",
      ">>> TF: 36551.5, Torch: 36551.4765625\n",
      ">>> TF: 0.8670288920402527, Torch: 0.8422128558158875\n",
      "Working on seed=87\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "euler_solver() got an unexpected keyword argument 'mask'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[98], line 24\u001b[0m\n\u001b[1;32m     22\u001b[0m torch_cellbox\u001b[39m.\u001b[39mtrain()\n\u001b[1;32m     23\u001b[0m \u001b[39mif\u001b[39;00m torch_args\u001b[39m.\u001b[39mpert_form \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mby u\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m---> 24\u001b[0m     prediction \u001b[39m=\u001b[39m torch_cellbox(torch\u001b[39m.\u001b[39;49mzeros((args\u001b[39m.\u001b[39;49mn_x, \u001b[39m1\u001b[39;49m), dtype\u001b[39m=\u001b[39;49mtorch\u001b[39m.\u001b[39;49mfloat32), torch\u001b[39m.\u001b[39;49mtensor(data[\u001b[39m\"\u001b[39;49m\u001b[39minp\u001b[39;49m\u001b[39m\"\u001b[39;49m], dtype\u001b[39m=\u001b[39;49mtorch\u001b[39m.\u001b[39;49mfloat32))\n\u001b[1;32m     25\u001b[0m \u001b[39melif\u001b[39;00m torch_args\u001b[39m.\u001b[39mpert_form \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mfix x\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m     26\u001b[0m     prediction \u001b[39m=\u001b[39m model(\n\u001b[1;32m     27\u001b[0m         torch\u001b[39m.\u001b[39mtensor(data[\u001b[39m\"\u001b[39m\u001b[39minp\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mT, dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mfloat32),\n\u001b[1;32m     28\u001b[0m         torch\u001b[39m.\u001b[39mtensor(data[\u001b[39m\"\u001b[39m\u001b[39minp\u001b[39m\u001b[39m\"\u001b[39m], dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mfloat32)\n\u001b[1;32m     29\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/cellbox-3.6-2/lib/python3.8/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Documents/cellbox-jun-6/cellbox/cellbox/model_torch.py:102\u001b[0m, in \u001b[0;36mCellBox.forward\u001b[0;34m(self, y0, mu)\u001b[0m\n\u001b[1;32m    100\u001b[0m mu_t \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtranspose(mu, \u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m)\n\u001b[1;32m    101\u001b[0m mask \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_mask()\n\u001b[0;32m--> 102\u001b[0m ys \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mode_solver(y0, mu_t, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49margs\u001b[39m.\u001b[39;49mdT, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49margs\u001b[39m.\u001b[39;49mn_T, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dxdt, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgradient_zero_from, mask\u001b[39m=\u001b[39;49mmask)\n\u001b[1;32m    103\u001b[0m \u001b[39m# [n_T, n_x, batch_size]\u001b[39;00m\n\u001b[1;32m    104\u001b[0m ys \u001b[39m=\u001b[39m ys[\u001b[39m-\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mode_last_steps:]\n",
      "\u001b[0;31mTypeError\u001b[0m: euler_solver() got an unexpected keyword argument 'mask'"
     ]
    }
   ],
   "source": [
    "for seed, lamb, other in zip(seeds, lambdas, others):\n",
    "    print(f\"Working on {seed=}\")\n",
    "    with open(f\"/users/ngun7t/Documents/cellbox-jun-6/test_arrays/forward_pass/forward_input_{seed}_{lamb[0]}_{lamb[1]}.pkl\", \"rb\") as f:\n",
    "        data = pickle.load(f)\n",
    "    with open(f\"/users/ngun7t/Documents/cellbox-jun-6/test_arrays/forward_pass/forward_out_{seed}_{lamb[0]}_{lamb[1]}.pkl\", \"rb\") as f:\n",
    "        data_out = pickle.load(f)\n",
    "\n",
    "    torch_args.envelope_form = other[0]\n",
    "    torch_args.ode_solver = other[1]\n",
    "    torch_args.n_T = other[2]\n",
    "    torch_args.pert_form = other[3]\n",
    "    torch_cellbox = cellbox.model_torch.factory(torch_args)[0]\n",
    "    \n",
    "\n",
    "    for w in torch_cellbox.named_parameters():\n",
    "        if w[0] == \"params.W\": w[1].data = torch.tensor(data[\"W\"], dtype=torch.float32)\n",
    "\n",
    "    l1_lambda = data[\"l1_lambda\"]\n",
    "    l2_lambda = data[\"l2_lambda\"]\n",
    "    loss_fn = cellbox.utils_torch.loss\n",
    "\n",
    "    torch_cellbox.train()\n",
    "    if torch_args.pert_form == \"by u\":\n",
    "        prediction = torch_cellbox(torch.zeros((args.n_x, 1), dtype=torch.float32), torch.tensor(data[\"inp\"], dtype=torch.float32))\n",
    "    elif torch_args.pert_form == \"fix x\":\n",
    "        prediction = model(\n",
    "            torch.tensor(data[\"inp\"].T, dtype=torch.float32),\n",
    "            torch.tensor(data[\"inp\"], dtype=torch.float32)\n",
    "        )\n",
    "    #prediction = torch_cellbox(torch.zeros((args.n_x, 1), dtype=torch.float32), torch.tensor(data[\"inp\"], dtype=torch.float32))\n",
    "    convergence_metric, yhat = prediction\n",
    "\n",
    "    for param in torch_cellbox.named_parameters():\n",
    "        if param[0] == \"params.W\":\n",
    "            param_mat = param[1]\n",
    "            break\n",
    "\n",
    "    loss_train_i_torch, loss_train_mse_i_torch = loss_fn(torch.tensor(out, dtype=torch.float32), yhat, param_mat, l1=l1_lambda, l2=l2_lambda)\n",
    "    print(f\">>> TF: {data_out['loss_train']}, Torch: {loss_train_i_torch.item()}\")\n",
    "    print(f\">>> TF: {data_out['loss_train_mse']}, Torch: {loss_train_mse_i_torch.item()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cellbox-3.6-2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
